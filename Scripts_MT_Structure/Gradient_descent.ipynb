{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists, join, isfile\n",
    "from os import listdir, makedirs\n",
    "from obspy.geodetics import kilometer2degrees\n",
    "from obspy.taup import TauPyModel\n",
    "from scipy.optimize import approx_fprime as af\n",
    "import obspy\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import Create_Vmod\n",
    "from SS_MTI import Gradient, PhaseTracer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_OG = \"/home/nienke/Documents/Research/SS_MTI/External_packages/Test_reflectivity/m0_gradient_descent/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(join(save_path_OG, \"start_v\")):\n",
    "    makedirs(join(save_path_OG, \"start_v\"))\n",
    "f_start = join(save_path_OG, \"start_v\")\n",
    "bin_path = \"/home/nienke/Documents/Research/SS_MTI/External_packages/reflectivity_Mars/SRC/test/crfl_sac\"\n",
    "# if not listdir(save_path):\n",
    "#     subprocess.call(f\"scp {bin_path} .\", shell=True, cwd=f_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_depth = 20.0\n",
    "epi_in_km = 1774.7380\n",
    "epi = kilometer2degrees(epi_in_km, radius=3389.5)\n",
    "baz = 0.0\n",
    "\n",
    "dt = 0.025\n",
    "\n",
    "phases = [\"P\", \"S\", \"P\", \"S\", \"S\"]\n",
    "comps = [\"Z\", \"T\", \"R\", \"Z\", \"R\"]\n",
    "t_pres = [1, 1, 1, 1, 1]\n",
    "t_posts = [30, 30, 30, 30, 30]\n",
    "ylims = [1e-9, 1e-9, 2e-9, 3e-9, 2e-9]\n",
    "\n",
    "fmin = 0.2\n",
    "fmax = 0.6\n",
    "zerophase = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_observed = (\n",
    "    \"/home/nienke/Documents/Research/SS_MTI/External_packages/Test_reflectivity/obs/\"\n",
    ")\n",
    "npz_file = \"/home/nienke/Documents/Research/Data/npz_files/TAYAK.npz\"\n",
    "st_obs = Gradient.read_refl_mseeds(path=path_observed)\n",
    "Taup = TauPyModel(npz_file)\n",
    "obs_tts = [PhaseTracer.get_traveltime(Taup, phase, src_depth, epi) for phase in phases]\n",
    "st_obs_w, st_obs_full, s_obs = Gradient.window(\n",
    "    st_obs, phases, comps, obs_tts, t_pres, t_posts, fmin, fmax, zerophase,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_start_model = \"/home/nienke/Documents/Research/Data/MTI/MT_vs_STR/bm_models/TAYAK.bm\"\n",
    "m_rr = 0.2\n",
    "m_tt = 0.8\n",
    "m_pp = 0.0\n",
    "m_rt = 0.0\n",
    "m_rp = 0.0\n",
    "m_tp = 0.0\n",
    "focal_mech = [m_rr, m_tt, m_pp, m_rt, m_rp, m_tp]\n",
    "Moho_d = 77.3680\n",
    "\n",
    "# Create_Vmod.create_dat_file(\n",
    "#     src_depth, epi_in_km, baz, focal_mech, dt, f_start, bm_start_model,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = np.hstack((focal_mech, Moho_d))\n",
    "np.save(join(f_start, \"m0.npy\"), m0)\n",
    "sigmas = np.ones(len(phases)) * 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update 1: Epsilon test\n",
    "i.e., testing various epsilon (step size) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Update_nr = 1\n",
    "if not exists(join(save_path_OG, f\"Update_{Update_nr}\")):\n",
    "    makedirs(join(save_path_OG, f\"Update_{Update_nr}\"))\n",
    "save_path = join(save_path_OG, f\"Update_{Update_nr}\")\n",
    "src_str = Gradient.SRC_STR(\n",
    "    binary_file_path=bin_path,\n",
    "    prior_dat_filepath=join(f_start, \"crfl.dat\"),\n",
    "    save_folder=save_path,\n",
    "    phases=phases,\n",
    "    components=comps,\n",
    "    t_pres=t_pres,\n",
    "    t_posts=t_posts,\n",
    "    depth=True,\n",
    "    vpvs=False,\n",
    "    fmin=fmin,\n",
    "    fmax=fmax,\n",
    "    dt=dt,\n",
    "    sigmas=sigmas,\n",
    "    zerophase=zerophase,\n",
    "    start_it=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epsilons = [-1e-10, -1e-5, -0.0001, -0.001, -0.01, 1e-10, 1e-5, 0.0001, 0.001, 0.01]\n",
    "dxi_dms = np.zeros((len(m0), len(epsilons)))\n",
    "if not isfile(join(save_path, \"dxi_dms.npy\")):\n",
    "    for i, epsilon in enumerate(epsilons):\n",
    "        dxi_dm = af(\n",
    "            m0,\n",
    "            src_str.misfit,\n",
    "            epsilon\n",
    "            * np.array(\n",
    "                [\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    m0[-1],\n",
    "                ]\n",
    "            ),\n",
    "            st_obs_w,\n",
    "        )\n",
    "        dxi_dms[:, i] = dxi_dm\n",
    "        np.save(join(save_path, \"dxi_dms.npy\"), dxi_dms)\n",
    "else:\n",
    "    print(\"dxi_dms.npy already exists in this folder, reads in the existing file\")\n",
    "    dxi_dms = np.load(join(save_path, \"dxi_dms.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: Testing epsilon\n",
    "If we plot the gradient for each model paramater for each epsilon that we testen, we see that an epsilon of 0.01 and 0.001 (also -0.01 and -0.001) show similar trends in the misfit w.r.t. the model parameters. This means that we can trust this epsilon value the most out of the ones that we have tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=dxi_dms.shape[1], ncols=1, sharex=\"all\", figsize=(6, 30))\n",
    "\n",
    "ming, maxg = (\n",
    "    dxi_dms.min(),\n",
    "    dxi_dms.max(),\n",
    ")\n",
    "\n",
    "for i, eps in enumerate(epsilons):\n",
    "    ax[i].plot(dxi_dms[:, i], label=f\"grad {i}, Epsilon {eps}\", alpha=0.5)\n",
    "\n",
    "    ax[i].set_ylim([ming, maxg])\n",
    "    ax[i].legend(fontsize = 15)\n",
    "    ax[i].tick_params(axis=\"both\", which=\"major\", labelsize=15)\n",
    "ax[-1].set_xlabel(\"m\", fontsize=20)\n",
    "ax[-1].set_xticklabels([\"No\", \"m_rr\", \"m_tt\", \"m_pp\", \"m_rt\", \"m_rp\", \"m_tp\", \"moho-d\"])\n",
    "ax[i].tick_params(axis=\"both\", which=\"major\", labelsize=15)\n",
    "# ax.tick_params(axis=\"both\", which=\"minor\", labelsize=15)\n",
    "# ax.set_xlabel(\"Update nr\", fontsize=20)\n",
    "# ax.set_ylabel(\"Misfit\", fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing alpha for  selected epsilons\n",
    "We have tested that an epsilon value of 0.001 seems to be reasonable. Now, we know that when we just use the gradient (event with an \"optimal\" epsilon of 0.001) and subtract it from current model, within a few steps our model blows up. This is coming from the fact that we need to take smaller steps rather than updating with the full gradient. So the next testing phase will look like this:\n",
    "1. We use an epsilon of 0.001 (compromise between 0.001) to calculate the gradient\n",
    "2. Once we have the gradient, we determine our alpha (i.e., what kind of percentage of the gradient we want to subtract from our model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 1: First we recompute the gradient with m0 with the chosen epsilon value of 0.001\"\"\"\n",
    "epsilon = 0.001\n",
    "if not isfile(join(save_path, f\"dX0_dm_{epsilon}.npy\")):\n",
    "    X0 = src_str.misfit(m0, st_obs_w)\n",
    "    dX0_dm = af(\n",
    "        m0,\n",
    "        src_str.misfit,\n",
    "        epsilon\n",
    "        * np.array(\n",
    "            [\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                m0[-1],\n",
    "            ]\n",
    "        ),\n",
    "        st_obs_w,\n",
    "    )\n",
    "    np.save(join(save_path, f\"dX0_dm_{epsilon}.npy\"), dX0_dm)\n",
    "    np.save(join(save_path, f\"X0_{epsilon}.npy\"), X0)\n",
    "    np.save(join(save_path, f\"m0_{epsilon}.npy\"), m0)\n",
    "else:\n",
    "    dX0_dm = np.load(join(save_path, f\"dX0_dm_{epsilon}.npy\"))\n",
    "    X0 = np.load(join(save_path, f\"X0_{epsilon}.npy\"))\n",
    "    m0 = np.load(join(save_path, f\"m0_{epsilon}.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 2: We look at the misfits when we update our m0 to m1 with various alpha steps\"\"\"\n",
    "alphas = [1e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 1e-2, 1e-1]\n",
    "if not isfile(join(save_path, f\"m1s_{epsilon}.npy\")):\n",
    "    m1s = np.zeros((len(m0), len(alphas)))\n",
    "    X1s = np.zeros(len(alphas))\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        m1s[:, i] = m0 - dX0_dm * alpha\n",
    "\n",
    "        X1s[i] = src_str.misfit(m1s[:, i], st_obs_w)\n",
    "    np.save(join(save_path, f\"m1s_{epsilon}.npy\"), m1s)\n",
    "    np.save(join(save_path, f\"X1s_{epsilon}.npy\"), X1s)\n",
    "else:\n",
    "    m1s = np.load(join(save_path, f\"m1s_{epsilon}.npy\"))\n",
    "    X1s = np.load(join(save_path, f\"X1s_{epsilon}.npy\"))\n",
    "\n",
    "min_misfit = X1s.argmin()\n",
    "min_alpha = alphas[min_misfit]\n",
    "m1 = m1s[:, min_misfit]\n",
    "np.save(join(save_path_OG, f\"Update_{Update_nr}\", f\"m1_{epsilon}.npy\"), m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=\"all\", figsize=(8, 8))\n",
    "ax.loglog(alphas, X1s)\n",
    "ax.grid(True, which=\"both\")\n",
    "ax.set_ylabel(\"misfit\", fontsize=20)\n",
    "ax.set_xlabel(\"alpha values\", fontsize=20)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare waveforms of m0 and m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isfile(join(save_path, \"st_m0.mseed\")):\n",
    "    st_m0 = src_str.forward(m0)\n",
    "    st_m0.write(join(save_path, \"st_m0.mseed\"), format=\"MSEED\")\n",
    "else:\n",
    "    st_m0 = obspy.read(join(save_path, \"st_m0.mseed\"))\n",
    "\n",
    "if not isfile(join(save_path, \"st_m1.mseed\")):\n",
    "    st_m1 = src_str.forward(m1)\n",
    "    st_m1.write(join(save_path, \"st_m1.mseed\"), format=\"MSEED\")\n",
    "else:\n",
    "    st_m1 = obspy.read(join(save_path, \"st_m1.mseed\"))\n",
    "\n",
    "\"\"\" Window the data \"\"\"\n",
    "m0_tts = Gradient.get_tt_from_dat_file(src_str.phases, join(save_path, \"It_97\"), m0[-1])\n",
    "st_m0_w, st_m0_full, s_m0 = Gradient.window(\n",
    "    st_m0,\n",
    "    src_str.phases,\n",
    "    src_str.components,\n",
    "    m0_tts,\n",
    "    src_str.t_pres,\n",
    "    src_str.t_posts,\n",
    "    src_str.fmin,\n",
    "    src_str.fmax,\n",
    "    src_str.zerophase,\n",
    ")\n",
    "\n",
    "m1_tts = Gradient.get_tt_from_dat_file(src_str.phases, join(save_path, \"It_98\"), m1[-1])\n",
    "st_m1_w, st_m1_full, s_m1 = Gradient.window(\n",
    "    st_m1,\n",
    "    src_str.phases,\n",
    "    src_str.components,\n",
    "    m1_tts,\n",
    "    src_str.t_pres,\n",
    "    src_str.t_posts,\n",
    "    src_str.fmin,\n",
    "    src_str.fmax,\n",
    "    src_str.zerophase,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=len(phases), ncols=1, sharex=\"all\", figsize=(18, 20))\n",
    "for i, (tr_obs, tr_m0, tr_m1) in enumerate(zip(st_obs_w, st_m0_w, st_m1_w)):\n",
    "    ax[i].plot(\n",
    "        tr_obs.times() - t_pres[i], tr_obs.data, lw=3, c=\"k\", label=\"Observed\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m0.times() - t_pres[i], tr_m0.data, lw=3, c=\"b\", label=\"m0\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m1.times() - t_pres[i], tr_m1.data, lw=3, c=\"r\", label=\"m1\",\n",
    "    )\n",
    "for i, (tr_obs, tr_m0, tr_m1) in enumerate(zip(st_obs_full, st_m0_full, st_m1_full)):\n",
    "    ax[i].plot(\n",
    "        tr_obs.times() - obs_tts[i], tr_obs.data, lw=1, c=\"k\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m0.times() - m0_tts[i], tr_m0.data, lw=1, c=\"b\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m1.times() - m1_tts[i], tr_m1.data, lw=1, c=\"r\",\n",
    "    )\n",
    "\n",
    "    ax[i].text(\n",
    "        s=f\"{phases[i]}{comps[i]}\",\n",
    "        x=0.99,\n",
    "        y=0.75,\n",
    "        ha=\"right\",\n",
    "        transform=ax[i].transAxes,\n",
    "        color=\"blue\",\n",
    "        fontsize=40,\n",
    "    )\n",
    "    ax[i].tick_params(axis=\"both\", which=\"major\", labelsize=35)\n",
    "    ax[i].get_yaxis().get_offset_text().set_visible(False)\n",
    "    ax_max = max(ax[i].get_yticks())\n",
    "    exponent_axis = np.floor(np.log10(ax_max)).astype(int)\n",
    "    ax[i].annotate(\n",
    "        r\"$\\times$10$^{%i}$\" % (exponent_axis),\n",
    "        xy=(0.01, 0.75),\n",
    "        xycoords=\"axes fraction\",\n",
    "        fontsize=32,\n",
    "    )\n",
    "    if ylims is None:\n",
    "        global_max = max([tr.data.max() for tr in st_obs_w]) * 1.2\n",
    "        global_min = min([tr.data.min() for tr in st_obs_w]) * 1.2\n",
    "        ax[i].set_ylim(global_min, global_max)\n",
    "    else:\n",
    "        ax[i].set_ylim(-ylims[i], ylims[i])\n",
    "    ymax = ax[i].get_ylim()[1]\n",
    "    ax[i].axvline(x=t_posts[i], c=\"grey\", ls=\"dashed\")\n",
    "    ax[i].axvline(x=-t_pres[i], c=\"grey\", ls=\"dashed\")\n",
    "    ax[i].axvline(x=0.0, c=\"dimgrey\", lw=2)\n",
    "    ax[i].text(\n",
    "        0 + 0.1,\n",
    "        ymax * 0.8,\n",
    "        phases[i],\n",
    "        verticalalignment=\"center\",\n",
    "        color=\"dimgray\",\n",
    "        fontsize=30,\n",
    "    )\n",
    "\n",
    "fig.text(0.01, 0.5, \"Displacement (nm)\", va=\"center\", rotation=\"vertical\", fontsize=45)\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.88,\n",
    "    \"Update 1\",\n",
    "    ha=\"center\",\n",
    "    va=\"bottom\",\n",
    "    size=\"x-large\",\n",
    "    color=\"red\",\n",
    "    fontsize=45,\n",
    ")\n",
    "\n",
    "ax[0].legend(\n",
    "    prop={\"size\": 35},\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0.12, 0.93),\n",
    "    bbox_transform=fig.transFigure,\n",
    ")\n",
    "\n",
    "ax[-1].set_xlim(-10.0, 32.0)\n",
    "ax[-1].set_xlabel(\"time after phase (s)\", fontsize=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2:\n",
    "We found that m0 -> m1 halved the misfit value and also if we look at the waveform fits, m1 fits the data better than m0. Now we can take our m1 as our m0 value and prepare for a new update.\n",
    "1. We need to determine the epsilon again (to see if the epsilon of 0.01 is still a good choice)\n",
    "2. We need to determine the alpha again (this needs to be done always, like a line search basically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_file_path_m1 = join(save_path_OG, \"Update_1\", \"It_98\")\n",
    "m1 = np.load(join(save_path_OG, \"Update_1\", \"m1_0.001.npy\"))\n",
    "\n",
    "m0 = m1\n",
    "Update_nr += 1\n",
    "if not exists(join(save_path_OG, f\"Update_{Update_nr}\")):\n",
    "    makedirs(join(save_path_OG, f\"Update_{Update_nr}\"))\n",
    "save_path = join(save_path_OG, f\"Update_{Update_nr}\")\n",
    "\n",
    "src_str = Gradient.SRC_STR(\n",
    "    binary_file_path=bin_path,\n",
    "    prior_dat_filepath=join(dat_file_path_m1, \"crfl.dat\"),\n",
    "    save_folder=save_path,\n",
    "    phases=phases,\n",
    "    components=comps,\n",
    "    t_pres=t_pres,\n",
    "    t_posts=t_posts,\n",
    "    depth=True,\n",
    "    vpvs=False,\n",
    "    fmin=fmin,\n",
    "    fmax=fmax,\n",
    "    dt=dt,\n",
    "    sigmas=sigmas,\n",
    "    zerophase=zerophase,\n",
    "    start_it=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test epsilon again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [-1e-10, -1e-5, -0.0001, -0.001, -0.01, 1e-10, 1e-5, 0.0001, 0.001, 0.01]\n",
    "dxi_dms = np.zeros((len(m0), len(epsilons)))\n",
    "if not isfile(join(save_path, \"dxi_dms.npy\")):\n",
    "    for i, epsilon in enumerate(epsilons):\n",
    "\n",
    "        dxi_dm = af(\n",
    "            m0,\n",
    "            src_str.misfit,\n",
    "            epsilon\n",
    "            * np.array(\n",
    "                [\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    np.mean(m0[:-1]),\n",
    "                    m0[-1],\n",
    "                ]\n",
    "            ),\n",
    "            st_obs_w,\n",
    "        )\n",
    "        dxi_dms[:, i] = dxi_dm\n",
    "        np.save(join(save_path, \"dxi_dms.npy\"), dxi_dms)\n",
    "else:\n",
    "    print(\"dxi_dms.npy already exists in this folder, reads in the existing file\")\n",
    "    dxi_dms = np.load(join(save_path, \"dxi_dms.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=dxi_dms.shape[1], ncols=1, sharex=\"all\", figsize=(4, 20))\n",
    "\n",
    "ming, maxg = (\n",
    "    dxi_dms.min(),\n",
    "    dxi_dms.max(),\n",
    ")\n",
    "\n",
    "for i, eps in enumerate(epsilons):\n",
    "    ax[i].plot(dxi_dms[:, i], label=f\"grad {i}, Epsilon {eps}\", alpha=0.5)\n",
    "\n",
    "    ax[i].set_ylim([ming, maxg])\n",
    "    ax[i].legend()\n",
    "ax[-1].set_xlabel(\"m\")\n",
    "ax[-1].set_xticklabels([\"No\", \"m_rr\", \"m_tt\", \"m_pp\", \"m_rt\", \"m_rp\", \"m_tp\", \"moho-d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that an epsilon of 0.01 is now going a bit too steep for the moho-d update, so we choose the epsilon of 0.001 this time. It seems that may be the epsilon of 0.01 is a little bit of a too large step for the moho depth, but it seems that it is good for the moment tensor parameters. Therefore, it could be a good idea, for the next gradient update, to multiply the depth parameter with 0.1 times the epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Alpha again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.001\n",
    "\"\"\" Step 2: We look at the misfits when we update our m0 to m1 with various alpha steps\"\"\"\n",
    "alphas = [1e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 1e-2, 1e-1]\n",
    "if not isfile(join(save_path, f\"m1s_{epsilon}.npy\")):\n",
    "    m1s = np.zeros((len(m0), len(alphas)))\n",
    "    X1s = np.zeros(len(alphas))\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        m1s[:, i] = m0 - dX0_dm * alpha\n",
    "\n",
    "        X1s[i] = src_str.misfit(m1s[:, i], st_obs_w)\n",
    "    np.save(join(save_path, f\"m1s_{epsilon}.npy\"), m1s)\n",
    "    np.save(join(save_path, f\"X1s_{epsilon}.npy\"), X1s)\n",
    "else:\n",
    "    m1s = np.load(join(save_path, f\"m1s_{epsilon}.npy\"))\n",
    "    X1s = np.load(join(save_path, f\"X1s_{epsilon}.npy\"))\n",
    "\n",
    "min_misfit = X1s.argmin()\n",
    "min_alpha = alphas[min_misfit]\n",
    "m1 = m1s[:, min_misfit]\n",
    "np.save(join(save_path_OG, f\"Update_{Update_nr}\", f\"m1_{epsilon}.npy\"), m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=\"all\", figsize=(8, 8))\n",
    "ax.loglog(alphas, X1s)\n",
    "ax.grid(True, which=\"both\")\n",
    "ax.set_ylabel(\"misfit\", fontsize=20)\n",
    "ax.set_xlabel(\"alpha values\", fontsize=20)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare m0 and m1 from iteration 2 (with chosen epsilon and alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isfile(join(save_path, \"st_m0.mseed\")):\n",
    "    st_m0 = src_str.forward(m0)\n",
    "    st_m0.write(join(save_path, \"st_m0.mseed\"), format=\"MSEED\")\n",
    "else:\n",
    "    st_m0 = obspy.read(join(save_path, \"st_m0.mseed\"))\n",
    "\n",
    "if not isfile(join(save_path, \"st_m1.mseed\")):\n",
    "    st_m1 = src_str.forward(m1)\n",
    "    st_m1.write(join(save_path, \"st_m1.mseed\"), format=\"MSEED\")\n",
    "else:\n",
    "    st_m1 = obspy.read(join(save_path, \"st_m1.mseed\"))\n",
    "\n",
    "\"\"\" Window the data \"\"\"\n",
    "m0_tts = Gradient.get_tt_from_dat_file(src_str.phases, join(save_path, \"It_88\"), m0[-1])\n",
    "st_m0_w, st_m0_full, s_m0 = Gradient.window(\n",
    "    st_m0,\n",
    "    src_str.phases,\n",
    "    src_str.components,\n",
    "    m0_tts,\n",
    "    src_str.t_pres,\n",
    "    src_str.t_posts,\n",
    "    src_str.fmin,\n",
    "    src_str.fmax,\n",
    "    src_str.zerophase,\n",
    ")\n",
    "\n",
    "m1_tts = Gradient.get_tt_from_dat_file(src_str.phases, join(save_path, \"It_89\"), m1[-1])\n",
    "st_m1_w, st_m1_full, s_m1 = Gradient.window(\n",
    "    st_m1,\n",
    "    src_str.phases,\n",
    "    src_str.components,\n",
    "    m1_tts,\n",
    "    src_str.t_pres,\n",
    "    src_str.t_posts,\n",
    "    src_str.fmin,\n",
    "    src_str.fmax,\n",
    "    src_str.zerophase,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_m_start = obspy.read(join(save_path_OG,\"Update_1\",\"st_m0.mseed\"))\n",
    "fig, ax = plt.subplots(nrows=len(phases), ncols=1, sharex=\"all\", figsize=(18, 20))\n",
    "for i, (tr_obs, tr_m0, tr_m1) in enumerate(zip(st_obs_w, st_m0_w, st_m1_w)):\n",
    "    ax[i].plot(\n",
    "        tr_obs.times() - t_pres[i], tr_obs.data, lw=3, c=\"k\", label=\"Observed\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m0.times() - t_pres[i], tr_m0.data, lw=3, c=\"r\", label=\"m1\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m1.times() - t_pres[i], tr_m1.data, lw=3, c=\"g\", label=\"m2\",\n",
    "    )\n",
    "for i, (tr_obs, tr_m0, tr_m1) in enumerate(zip(st_obs_full, st_m0_full, st_m1_full)):\n",
    "    ax[i].plot(\n",
    "        tr_obs.times() - obs_tts[i], tr_obs.data, lw=1, c=\"k\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m0.times() - m0_tts[i], tr_m0.data, lw=1, c=\"r\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m1.times() - m1_tts[i], tr_m1.data, lw=1, c=\"g\",\n",
    "    )\n",
    "\n",
    "    ax[i].text(\n",
    "        s=f\"{phases[i]}{comps[i]}\",\n",
    "        x=0.99,\n",
    "        y=0.75,\n",
    "        ha=\"right\",\n",
    "        transform=ax[i].transAxes,\n",
    "        color=\"blue\",\n",
    "        fontsize=40,\n",
    "    )\n",
    "    ax[i].tick_params(axis=\"both\", which=\"major\", labelsize=35)\n",
    "    ax[i].get_yaxis().get_offset_text().set_visible(False)\n",
    "    ax_max = max(ax[i].get_yticks())\n",
    "    exponent_axis = np.floor(np.log10(ax_max)).astype(int)\n",
    "    ax[i].annotate(\n",
    "        r\"$\\times$10$^{%i}$\" % (exponent_axis),\n",
    "        xy=(0.01, 0.75),\n",
    "        xycoords=\"axes fraction\",\n",
    "        fontsize=32,\n",
    "    )\n",
    "    if ylims is None:\n",
    "        global_max = max([tr.data.max() for tr in st_obs_w]) * 1.2\n",
    "        global_min = min([tr.data.min() for tr in st_obs_w]) * 1.2\n",
    "        ax[i].set_ylim(global_min, global_max)\n",
    "    else:\n",
    "        ax[i].set_ylim(-ylims[i], ylims[i])\n",
    "    ymax = ax[i].get_ylim()[1]\n",
    "    ax[i].axvline(x=t_posts[i], c=\"grey\", ls=\"dashed\")\n",
    "    ax[i].axvline(x=-t_pres[i], c=\"grey\", ls=\"dashed\")\n",
    "    ax[i].axvline(x=0.0, c=\"dimgrey\", lw=2)\n",
    "    ax[i].text(\n",
    "        0 + 0.1,\n",
    "        ymax * 0.8,\n",
    "        phases[i],\n",
    "        verticalalignment=\"center\",\n",
    "        color=\"dimgray\",\n",
    "        fontsize=30,\n",
    "    )\n",
    "\n",
    "fig.text(0.01, 0.5, \"Displacement (nm)\", va=\"center\", rotation=\"vertical\", fontsize=45)\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.88,\n",
    "    \"Update 2\",\n",
    "    ha=\"center\",\n",
    "    va=\"bottom\",\n",
    "    size=\"x-large\",\n",
    "    color=\"green\",\n",
    "    fontsize=45,\n",
    ")\n",
    "\n",
    "ax[0].legend(\n",
    "    prop={\"size\": 35},\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0.12, 0.93),\n",
    "    bbox_transform=fig.transFigure,\n",
    ")\n",
    "\n",
    "ax[-1].set_xlim(-10.0, 32.0)\n",
    "ax[-1].set_xlabel(\"time after phase (s)\", fontsize=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's go to update number 3!\n",
    "We have seen that epsilon 0.01 worked pretty good for the moment tensor, but was not optimal for the depth. The depth could be updated with 0.001. Therefore, for the next iteration, we choose to update with 0.01 and multiply the depth parameter with an extra 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_file_path_m1 = join(save_path_OG, \"Update_2\", \"It_89\")\n",
    "m1 = np.load(join(save_path_OG, \"Update_2\", \"m1_0.001.npy\"))\n",
    "\n",
    "m0 = m1\n",
    "Update_nr += 1\n",
    "if not exists(join(save_path_OG, f\"Update_{Update_nr}\")):\n",
    "    makedirs(join(save_path_OG, f\"Update_{Update_nr}\"))\n",
    "save_path = join(save_path_OG, f\"Update_{Update_nr}\")\n",
    "\n",
    "src_str = Gradient.SRC_STR(\n",
    "    binary_file_path=bin_path,\n",
    "    prior_dat_filepath=join(dat_file_path_m1, \"crfl.dat\"),\n",
    "    save_folder=save_path,\n",
    "    phases=phases,\n",
    "    components=comps,\n",
    "    t_pres=t_pres,\n",
    "    t_posts=t_posts,\n",
    "    depth=True,\n",
    "    vpvs=False,\n",
    "    fmin=fmin,\n",
    "    fmax=fmax,\n",
    "    dt=dt,\n",
    "    sigmas=sigmas,\n",
    "    zerophase=zerophase,\n",
    "    start_it=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.001\n",
    "dxi_dms = np.zeros((len(m0), 1))\n",
    "if not isfile(join(save_path, \"dxi_dms.npy\")):\n",
    "    dxi_dm = af(\n",
    "        m0,\n",
    "        src_str.misfit,\n",
    "        epsilon\n",
    "        * np.array(\n",
    "            [\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                np.mean(m0[:-1]),\n",
    "                m0[-1],\n",
    "            ]\n",
    "        ),\n",
    "        st_obs_w,\n",
    "    )\n",
    "    dxi_dms[:, 0] = dxi_dm\n",
    "    np.save(join(save_path, \"dxi_dms.npy\"), dxi_dms)\n",
    "else:\n",
    "    print(\"dxi_dms.npy already exists in this folder, reads in the existing file\")\n",
    "    dxi_dms = np.load(join(save_path, \"dxi_dms.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 2: We look at the misfits when we update our m0 to m1 with various alpha steps\"\"\"\n",
    "alphas = [1e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 1e-2, 1e-1]\n",
    "if not isfile(join(save_path, f\"m1s_{epsilon}.npy\")):\n",
    "    m1s = np.zeros((len(m0), len(alphas)))\n",
    "    X1s = np.zeros(len(alphas))\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        m1s[:, i] = m0 - dX0_dm * alpha\n",
    "\n",
    "        X1s[i] = src_str.misfit(m1s[:, i], st_obs_w)\n",
    "    np.save(join(save_path, f\"m1s_{epsilon}.npy\"), m1s)\n",
    "    np.save(join(save_path, f\"X1s_{epsilon}.npy\"), X1s)\n",
    "else:\n",
    "    m1s = np.load(join(save_path, f\"m1s_{epsilon}.npy\"))\n",
    "    X1s = np.load(join(save_path, f\"X1s_{epsilon}.npy\"))\n",
    "\n",
    "min_misfit = X1s.argmin()\n",
    "min_alpha = alphas[min_misfit]\n",
    "m1 = m1s[:, min_misfit]\n",
    "np.save(join(save_path_OG, f\"Update_{Update_nr}\", f\"m1_{epsilon}.npy\"), m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=\"all\", figsize=(8, 8))\n",
    "ax.loglog(alphas, X1s)\n",
    "ax.grid(True, which=\"both\")\n",
    "ax.set_ylabel(\"misfit\", fontsize=20)\n",
    "ax.set_xlabel(\"alpha values\", fontsize=20)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=15)\n",
    "# ax.set_ylim(1e2,1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isfile(join(save_path, \"st_m0.mseed\")):\n",
    "    st_m0 = src_str.forward(m0)\n",
    "    st_m0.write(join(save_path, \"st_m0.mseed\"), format=\"MSEED\")\n",
    "else:\n",
    "    st_m0 = obspy.read(join(save_path, \"st_m0.mseed\"))\n",
    "\n",
    "if not isfile(join(save_path, \"st_m1.mseed\")):\n",
    "    st_m1 = src_str.forward(m1)\n",
    "    st_m1.write(join(save_path, \"st_m1.mseed\"), format=\"MSEED\")\n",
    "else:\n",
    "    st_m1 = obspy.read(join(save_path, \"st_m1.mseed\"))\n",
    "\n",
    "\"\"\" Window the data \"\"\"\n",
    "m0_tts = Gradient.get_tt_from_dat_file(src_str.phases, join(save_path, \"It_16\"), m0[-1])\n",
    "st_m0_w, st_m0_full, s_m0 = Gradient.window(\n",
    "    st_m0,\n",
    "    src_str.phases,\n",
    "    src_str.components,\n",
    "    m0_tts,\n",
    "    src_str.t_pres,\n",
    "    src_str.t_posts,\n",
    "    src_str.fmin,\n",
    "    src_str.fmax,\n",
    "    src_str.zerophase,\n",
    ")\n",
    "\n",
    "m1_tts = Gradient.get_tt_from_dat_file(src_str.phases, join(save_path, \"It_17\"), m1[-1])\n",
    "st_m1_w, st_m1_full, s_m1 = Gradient.window(\n",
    "    st_m1,\n",
    "    src_str.phases,\n",
    "    src_str.components,\n",
    "    m1_tts,\n",
    "    src_str.t_pres,\n",
    "    src_str.t_posts,\n",
    "    src_str.fmin,\n",
    "    src_str.fmax,\n",
    "    src_str.zerophase,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=len(phases), ncols=1, sharex=\"all\", figsize=(18, 20))\n",
    "for i, (tr_obs, tr_m0, tr_m1) in enumerate(zip(st_obs_w, st_m0_w, st_m1_w)):\n",
    "    ax[i].plot(\n",
    "        tr_obs.times() - t_pres[i], tr_obs.data, lw=3, c=\"k\", label=\"Observed\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m0.times() - t_pres[i], tr_m0.data, lw=3, c=\"g\", label=\"m1\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m1.times() - t_pres[i], tr_m1.data, lw=3, c=\"purple\", label=\"m2\",\n",
    "    )\n",
    "for i, (tr_obs, tr_m0, tr_m1) in enumerate(zip(st_obs_full, st_m0_full, st_m1_full)):\n",
    "    ax[i].plot(\n",
    "        tr_obs.times() - obs_tts[i], tr_obs.data, lw=1, c=\"k\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m0.times() - m0_tts[i], tr_m0.data, lw=1, c=\"g\",\n",
    "    )\n",
    "    ax[i].plot(\n",
    "        tr_m1.times() - m1_tts[i], tr_m1.data, lw=1, c=\"purple\",\n",
    "    )\n",
    "\n",
    "    ax[i].text(\n",
    "        s=f\"{phases[i]}{comps[i]}\",\n",
    "        x=0.99,\n",
    "        y=0.75,\n",
    "        ha=\"right\",\n",
    "        transform=ax[i].transAxes,\n",
    "        color=\"blue\",\n",
    "        fontsize=40,\n",
    "    )\n",
    "    ax[i].tick_params(axis=\"both\", which=\"major\", labelsize=35)\n",
    "    ax[i].get_yaxis().get_offset_text().set_visible(False)\n",
    "    ax_max = max(ax[i].get_yticks())\n",
    "    exponent_axis = np.floor(np.log10(ax_max)).astype(int)\n",
    "    ax[i].annotate(\n",
    "        r\"$\\times$10$^{%i}$\" % (exponent_axis),\n",
    "        xy=(0.01, 0.75),\n",
    "        xycoords=\"axes fraction\",\n",
    "        fontsize=32,\n",
    "    )\n",
    "    if ylims is None:\n",
    "        global_max = max([tr.data.max() for tr in st_obs_w]) * 1.2\n",
    "        global_min = min([tr.data.min() for tr in st_obs_w]) * 1.2\n",
    "        ax[i].set_ylim(global_min, global_max)\n",
    "    else:\n",
    "        ax[i].set_ylim(-ylims[i], ylims[i])\n",
    "    ymax = ax[i].get_ylim()[1]\n",
    "    ax[i].axvline(x=t_posts[i], c=\"grey\", ls=\"dashed\")\n",
    "    ax[i].axvline(x=-t_pres[i], c=\"grey\", ls=\"dashed\")\n",
    "    ax[i].axvline(x=0.0, c=\"dimgrey\", lw=2)\n",
    "    ax[i].text(\n",
    "        0 + 0.1,\n",
    "        ymax * 0.8,\n",
    "        phases[i],\n",
    "        verticalalignment=\"center\",\n",
    "        color=\"dimgray\",\n",
    "        fontsize=30,\n",
    "    )\n",
    "\n",
    "fig.text(0.01, 0.5, \"Displacement (nm)\", va=\"center\", rotation=\"vertical\", fontsize=45)\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.88,\n",
    "    \"Update 3\",\n",
    "    ha=\"center\",\n",
    "    va=\"bottom\",\n",
    "    size=\"x-large\",\n",
    "    color=\"purple\",\n",
    "    fontsize=45,\n",
    ")\n",
    "\n",
    "ax[0].legend(\n",
    "    prop={\"size\": 35},\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0.12, 0.93),\n",
    "    bbox_transform=fig.transFigure,\n",
    ")\n",
    "\n",
    "ax[-1].set_xlim(-10.0, 32.0)\n",
    "ax[-1].set_xlabel(\"time after phase (s)\", fontsize=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New try: initial model a little bit worse!\n",
    "Now, we want to see what happens if our initial guess is a bit worse than before! Therefore, we change all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once this function workes properly, it should go into the inversion class defined as Gradient-descent!\n",
    "def gradient_descent(\n",
    "    bin_path: str,\n",
    "    save_path: str,\n",
    "    epsilon: float,\n",
    "    update_nr: int,\n",
    "    dt: float,\n",
    "    sigmas: [float],\n",
    "    current_update: int = 0,\n",
    "    prior_crfl_filepath: str = None,\n",
    "    alphas: [float] = [1e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 1e-2, 1e-1],\n",
    "    fmin: float = None,\n",
    "    fmax: float = None,\n",
    "    phases: [str] = [\"P\", \"S\", \"P\", \"S\", \"S\"],\n",
    "    comps: [str] = [\"Z\", \"T\", \"R\", \"Z\", \"R\"],\n",
    "    t_pres: [int] = [1, 1, 1, 1, 1],\n",
    "    t_posts: [int] = [30, 30, 30, 30, 30],\n",
    "):\n",
    "    \"\"\" \n",
    "    This function will do a gradient-descent step based on a line-search\n",
    "    :param bin_path: filepath to reflectivity binary\n",
    "    :param save_path: path where all updates will be saved\n",
    "    :param epsilon: step size w.r.t. each parameter\n",
    "    :param update_nr: amount of updates you want to do\n",
    "    :param dt: sampling rate [second/sample]\n",
    "    :param sigmas: expected standard deviation for each phase\n",
    "    :param current_update: current update nr, it restarts from previous update\n",
    "    :param prior_crfl_filepath: only necessary when update_nr = 0\n",
    "    :param alphas: gradient step sizes to test in the line search\n",
    "    :param fmin: highpass frequency band\n",
    "    :param fmax: lowpass frequency band\n",
    "    :param phases: phases to window\n",
    "    :param comps: components to window\n",
    "    :param t_pres: length before arrival\n",
    "    :param t_posts: length after arrival\n",
    "    \"\"\"\n",
    "\n",
    "    #     assert (\n",
    "    #         current_update == 0 and prior_crfl_filepath is not None\n",
    "    #     ), \"if current_update = 0, you have to specify filepath of your prior crfl.dat\"\n",
    "\n",
    "    save_path_OG = save_path\n",
    "\n",
    "    if current_update != 0:\n",
    "        \"\"\" Check where the previous update ended and take this crfl.dat file as prior file\"\"\"\n",
    "        prev_update = current_update - 1\n",
    "        prev_it = max(\n",
    "            [\n",
    "                int(f.strip(\"It_\"))\n",
    "                for f in listdir(join(save_path_OG, f\"Update_{prev_update}\"))\n",
    "                if f.startswith(\"It_\")\n",
    "            ]\n",
    "        )\n",
    "        prior_crfl_filepath = join(\n",
    "            save_path_OG, f\"Update_{prev_update}\", f\"It_{prev_it}\", \"crfl.dat\"\n",
    "        )\n",
    "        prev_m0 = [\n",
    "            f\n",
    "            for f in listdir(join(save_path, f\"Update_{prev_update}\"))\n",
    "            if f.startswith(\"m1_\")\n",
    "            if isfile(join(save_path, f\"Update_{prev_update}\", f))\n",
    "        ][0]\n",
    "        m0 = np.load(join(save_path_OG, f\"Update_{prev_update}\", prev_m0,))\n",
    "    else:\n",
    "        # NOTE: we have to convert fm parameters:\n",
    "        # reflectivity fm: mtt,mtp,mrt,mpp,mrp,mrr\n",
    "        # this code(also instaseis) fm: mrr,mtt,mpp,mrt,mrp,mtp\n",
    "        with open(prior_crfl_filepath, \"r\") as f:\n",
    "            data = f.readlines()\n",
    "            fm = np.array(data[-8].split(), dtype=float)\n",
    "        m0 = np.array(\n",
    "            [\n",
    "                fm[5],\n",
    "                fm[0],\n",
    "                fm[3],\n",
    "                fm[2],\n",
    "                -fm[4] + 0,\n",
    "                -fm[1] + 0,\n",
    "                float(data[8].split()[0]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    while current_update < update_nr:\n",
    "        if not exists(join(save_path_OG, f\"Update_{current_update}\")):\n",
    "            makedirs(join(save_path_OG, f\"Update_{current_update}\"))\n",
    "        save_path = join(save_path_OG, f\"Update_{current_update}\")\n",
    "\n",
    "        \"\"\" Calculating the gradient with given epsilon \"\"\"\n",
    "        src_str = Gradient.SRC_STR(\n",
    "            binary_file_path=bin_path,\n",
    "            prior_dat_filepath=prior_crfl_filepath,\n",
    "            save_folder=save_path,\n",
    "            phases=phases,\n",
    "            components=comps,\n",
    "            t_pres=t_pres,\n",
    "            t_posts=t_posts,\n",
    "            depth=True,\n",
    "            vpvs=False,\n",
    "            fmin=fmin,\n",
    "            fmax=fmax,\n",
    "            dt=dt,\n",
    "            sigmas=sigmas,\n",
    "            zerophase=zerophase,\n",
    "            start_it=0,\n",
    "        )\n",
    "\n",
    "        dxi_dms = np.zeros((len(m0), 1))\n",
    "        if not isfile(join(save_path, \"dxi_dms.npy\")):\n",
    "            dxi_dm = af(\n",
    "                m0,\n",
    "                src_str.misfit,\n",
    "                epsilon\n",
    "                * np.array(\n",
    "                    [\n",
    "                        np.mean(m0[:-1]),\n",
    "                        np.mean(m0[:-1]),\n",
    "                        np.mean(m0[:-1]),\n",
    "                        np.mean(m0[:-1]),\n",
    "                        np.mean(m0[:-1]),\n",
    "                        np.mean(m0[:-1]),\n",
    "                        0.1 * m0[-1],\n",
    "                    ]\n",
    "                ),\n",
    "                st_obs_w,\n",
    "            )\n",
    "            dxi_dms[:, 0] = dxi_dm\n",
    "            np.save(join(save_path, \"dxi_dms.npy\"), dxi_dms)\n",
    "        else:\n",
    "            print(\n",
    "                \"dxi_dms.npy already exists in this folder, reads in the existing file\"\n",
    "            )\n",
    "            dxi_dms = np.load(join(save_path, \"dxi_dms.npy\"))\n",
    "\n",
    "        \"\"\" Doing update using a line-search (i.e., update based on best alpha) \"\"\"\n",
    "        if not isfile(join(save_path, f\"m1s_{epsilon}.npy\")):\n",
    "            m1s = np.zeros((len(m0), len(alphas)))\n",
    "            X1s = np.zeros(len(alphas))\n",
    "            for i, alpha in enumerate(alphas):\n",
    "                m1s[:, i] = m0 - dxi_dm * alpha\n",
    "\n",
    "                X1s[i] = src_str.misfit(m1s[:, i], st_obs_w)\n",
    "            np.save(join(save_path, f\"m1s_{epsilon}.npy\"), m1s)\n",
    "            np.save(join(save_path, f\"X1s_{epsilon}.npy\"), X1s)\n",
    "        else:\n",
    "            m1s = np.load(join(save_path, f\"m1s_{epsilon}.npy\"))\n",
    "            X1s = np.load(join(save_path, f\"X1s_{epsilon}.npy\"))\n",
    "\n",
    "        min_misfit = X1s.argmin()\n",
    "        min_alpha = alphas[min_misfit]\n",
    "        m1 = m1s[:, min_misfit]\n",
    "        np.save(join(save_path, f\"m1_eps_{epsilon}_alpha_{min_alpha}.npy\"), m1)\n",
    "\n",
    "        \"\"\" Do a final forward run with the achieved m1 model: \"\"\"\n",
    "        st_m1 = src_str.forward(m1)\n",
    "        st_m1.write(join(save_path, \"st_m1.mseed\"), format=\"MSEED\")\n",
    "\n",
    "        \"\"\"\n",
    "        Make the latest iteration in this update, which is based on m1,\n",
    "        the new prior for the next update\n",
    "        \"\"\"\n",
    "        update_it = src_str.it - 1\n",
    "        print(f\"this is the iteration used for next update: {update_it}\")\n",
    "        prior_crfl_filepath = join(\n",
    "            save_path_OG, f\"Update_{current_update}\", f\"It_{update_it}\", \"crfl.dat\"\n",
    "        )\n",
    "\n",
    "        current_update += 1\n",
    "        m0 = m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = \"/home/nienke/Documents/Research/SS_MTI/External_packages/reflectivity_Mars/SRC/test/crfl_sac\"\n",
    "save_path_OG = \"/home/nienke/Documents/Research/SS_MTI/External_packages/Test_reflectivity/gradient_descent_2\"\n",
    "if not exists(join(save_path_OG, \"start_v\")):\n",
    "    makedirs(join(save_path_OG, \"start_v\"))\n",
    "f_start = join(save_path_OG, \"start_v\")\n",
    "\n",
    "## Fixed parameters:\n",
    "src_depth = 20.0\n",
    "epi_in_km = 1774.7380\n",
    "epi = kilometer2degrees(epi_in_km, radius=3389.5)\n",
    "baz = 0.0\n",
    "\n",
    "dt = 0.025\n",
    "\n",
    "phases = [\"P\", \"S\", \"P\", \"S\", \"S\"]\n",
    "comps = [\"Z\", \"T\", \"R\", \"Z\", \"R\"]\n",
    "t_pres = [1, 1, 1, 1, 1]\n",
    "t_posts = [30, 30, 30, 30, 30]\n",
    "ylims = [1e-9, 1e-9, 2e-9, 3e-9, 2e-9]\n",
    "\n",
    "fmin = 0.2\n",
    "fmax = 0.6\n",
    "zerophase = False\n",
    "\n",
    "\n",
    "## Start parameters:\n",
    "bm_start_model = \"/home/nienke/Documents/Research/Data/MTI/MT_vs_STR/bm_models/TAYAK.bm\"\n",
    "m_rr = 0.2\n",
    "m_tt = 0.3\n",
    "m_pp = -0.4\n",
    "m_rt = -0.2\n",
    "m_rp = 0.3\n",
    "m_tp = 0.8\n",
    "focal_mech = [m_rr, m_tt, m_pp, m_rt, m_rp, m_tp]\n",
    "Moho_d = 70.0\n",
    "\n",
    "Create_Vmod.create_dat_file(\n",
    "    src_depth, epi_in_km, baz, focal_mech, dt, f_start, bm_start_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = np.hstack((focal_mech, Moho_d))\n",
    "np.save(join(f_start, \"m0.npy\"), m0)\n",
    "sigmas = np.ones(len(phases)) * 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1e-4,1e-5]\n",
    "if not isfile(join(save_path, f\"m1s_{epsilon}.npy\")):\n",
    "    m1s = np.zeros((len(m0), len(alphas)))\n",
    "    X1s = np.zeros(len(alphas))\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        m1s[:, i] = m0 - dxi_dm * alpha\n",
    "\n",
    "        X1s[i] = src_str.misfit(m1s[:, i], st_obs_w)\n",
    "    np.save(join(save_path, f\"m1s_{epsilon}.npy\"), m1s)\n",
    "    np.save(join(save_path, f\"X1s_{epsilon}.npy\"), X1s)\n",
    "else:\n",
    "    m1s = np.load(join(save_path, f\"m1s_{epsilon}.npy\"))\n",
    "    X1s = np.load(join(save_path, f\"X1s_{epsilon}.npy\"))\n",
    "\n",
    "min_misfit = X1s.argmin()\n",
    "min_alpha = alphas[min_misfit]\n",
    "m1 = m1s[:, min_misfit]\n",
    "np.save(join(save_path, f\"alpha.npy\"),min_alpha)\n",
    "np.save(join(save_path, f\"misfit.npy\"),X1s.min())\n",
    "np.save(join(save_path, f\"m1_eps_{epsilon}.npy\"), m1)\n",
    "\n",
    "\"\"\" Do a final forward run with the achieved m1 model: \"\"\"\n",
    "st_m1 = src_str.forward(m1)\n",
    "st_m1.write(join(save_path, \"st_m1.mseed\"), format=\"MSEED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1s.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims = np.asarray(ylims) * 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_updates(\n",
    "    save_path,\n",
    "    st_obs_full,\n",
    "    st_obs_w,\n",
    "    phases,\n",
    "    comps,\n",
    "    t_pres,\n",
    "    t_posts,\n",
    "    fmin,\n",
    "    fmax,\n",
    "    zerophase,\n",
    "    ylims,\n",
    "):\n",
    "    fig, ax = plt.subplots(nrows=len(phases), ncols=1, sharex=\"all\", figsize=(18, 20))\n",
    "\n",
    "    update_folders = np.sort(\n",
    "        np.asarray(\n",
    "            [\n",
    "                int(f.strip(\"Update_\"))\n",
    "                for f in listdir(save_path)\n",
    "                if f.startswith(\"Update_\")\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    for up_nr in update_folders:\n",
    "        update_folder = join(save_path, f\"Update_{up_nr}\")\n",
    "        max_it = max(\n",
    "            [\n",
    "                int(f.strip(\"It_\"))\n",
    "                for f in listdir(join(save_path, update_folder))\n",
    "                if f.startswith(\"It_\")\n",
    "            ]\n",
    "        )\n",
    "        # Read in the data:\n",
    "        st_m = obspy.read(join(save_path, update_folder, \"st_m1.mseed\"))\n",
    "        m = np.load(\n",
    "            join(\n",
    "                save_path,\n",
    "                update_folder,\n",
    "                [\n",
    "                    f\n",
    "                    for f in listdir(join(save_path, update_folder))\n",
    "                    if f.startswith(\"m1_\")\n",
    "                    if isfile(join(save_path, update_folder, f))\n",
    "                ][0],\n",
    "            )\n",
    "        )\n",
    "        # Window the data:\n",
    "        npz_name = [\n",
    "            f\n",
    "            for f in listdir(join(save_path, update_folder, f\"It_{max_it}\"))\n",
    "            if f.endswith(\".npz\")\n",
    "            if isfile(join(save_path, update_folder, f\"It_{max_it}\", f))\n",
    "        ]\n",
    "        if npz_name:\n",
    "            npz_file = join(save_path, update_folder, f\"It_{max_it}\", npz_name[0],)\n",
    "            dat_file = join(save_path, update_folder, f\"It_{max_it}\",)\n",
    "\n",
    "            Taup = TauPyModel(npz_file)\n",
    "            depth = Create_Vmod.read_depth_from_dat(dat_file)\n",
    "            epi = Create_Vmod.read_epi_from_dat(dat_file)\n",
    "            m_tts = []\n",
    "            for i, phase in enumerate(phases):\n",
    "                m_tts.append(PhaseTracer.get_traveltime(Taup, phase, depth, epi))\n",
    "        else:\n",
    "            m_tts = Gradient.get_tt_from_dat_file(\n",
    "                phases, join(save_path, update_folder, f\"It_{max_it}\"), m[-1]\n",
    "            )\n",
    "\n",
    "        st_w, st_full, s_m = Gradient.window(\n",
    "            st_m, phases, comps, m_tts, t_pres, t_posts, fmin, fmax, zerophase,\n",
    "        )\n",
    "        if up_nr == 0:\n",
    "            alpha = 1 / len(update_folders)\n",
    "        else:\n",
    "            alpha = up_nr / len(update_folders)\n",
    "        for i, (tr_full, tr_w) in enumerate(zip(st_full, st_w)):\n",
    "            ax[i].plot(\n",
    "                tr_w.times() - t_pres[i],\n",
    "                tr_w.data,\n",
    "                lw=3,\n",
    "                c=\"b\",\n",
    "                alpha=alpha,\n",
    "                label=f\"m{up_nr}\",\n",
    "            )\n",
    "            ax[i].plot(\n",
    "                tr_full.times() - m_tts[i], tr_full.data, lw=3, alpha=alpha, c=\"b\",\n",
    "            )\n",
    "    for i, (tr_obs_full, tr_obs_w) in enumerate(zip(st_obs_full, st_obs_w)):\n",
    "        ax[i].plot(\n",
    "            tr_obs_full.times() - obs_tts[i],\n",
    "            tr_obs_full.data,\n",
    "            lw=1,\n",
    "            c=\"k\",\n",
    "            label=\"Observed\",\n",
    "        )\n",
    "        ax[i].plot(\n",
    "            tr_obs_w.times() - obs_tts[i], tr_obs_w.data, lw=1, c=\"k\",\n",
    "        )\n",
    "\n",
    "        ax[i].text(\n",
    "            s=f\"{phases[i]}{comps[i]}\",\n",
    "            x=0.99,\n",
    "            y=0.75,\n",
    "            ha=\"right\",\n",
    "            transform=ax[i].transAxes,\n",
    "            color=\"blue\",\n",
    "            fontsize=40,\n",
    "        )\n",
    "        ax[i].tick_params(axis=\"both\", which=\"major\", labelsize=35)\n",
    "        ax[i].get_yaxis().get_offset_text().set_visible(False)\n",
    "        ax_max = max(ax[i].get_yticks())\n",
    "        exponent_axis = np.floor(np.log10(ax_max)).astype(int)\n",
    "        ax[i].annotate(\n",
    "            r\"$\\times$10$^{%i}$\" % (exponent_axis),\n",
    "            xy=(0.01, 0.75),\n",
    "            xycoords=\"axes fraction\",\n",
    "            fontsize=32,\n",
    "        )\n",
    "        if ylims is None:\n",
    "            global_max = max([tr.data.max() for tr in st_obs_w]) * 1.2\n",
    "            global_min = min([tr.data.min() for tr in st_obs_w]) * 1.2\n",
    "            ax[i].set_ylim(global_min, global_max)\n",
    "        else:\n",
    "            ax[i].set_ylim(-ylims[i], ylims[i])\n",
    "        ymax = ax[i].get_ylim()[1]\n",
    "        ax[i].axvline(x=t_posts[i], c=\"grey\", ls=\"dashed\")\n",
    "        ax[i].axvline(x=-t_pres[i], c=\"grey\", ls=\"dashed\")\n",
    "        ax[i].axvline(x=0.0, c=\"dimgrey\", lw=2)\n",
    "        ax[i].text(\n",
    "            0 + 0.1,\n",
    "            ymax * 0.8,\n",
    "            phases[i],\n",
    "            verticalalignment=\"center\",\n",
    "            color=\"dimgray\",\n",
    "            fontsize=30,\n",
    "        )\n",
    "\n",
    "    fig.text(\n",
    "        0.01, 0.5, \"Displacement (nm)\", va=\"center\", rotation=\"vertical\", fontsize=45\n",
    "    )\n",
    "    fig.text(\n",
    "        0.5,\n",
    "        0.88,\n",
    "        \"Synthetic test\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        size=\"x-large\",\n",
    "        color=\"purple\",\n",
    "        fontsize=45,\n",
    "    )\n",
    "\n",
    "    ax[0].legend(\n",
    "        ncol=5,\n",
    "        prop={\"size\": 15},\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(0.12, 0.93),\n",
    "        bbox_transform=fig.transFigure,\n",
    "    )\n",
    "\n",
    "    ax[-1].set_xlim(-10.0, 32.0)\n",
    "    ax[-1].set_xlabel(\"time after phase (s)\", fontsize=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_updates(\n",
    "    save_path=\"/home/nienke/Documents/Research/SS_MTI/External_packages/Test_reflectivity/gradient_descent_2\",\n",
    "    st_obs_full=st_obs_full,\n",
    "    st_obs_w=st_obs_w,\n",
    "    phases=phases,\n",
    "    comps=comps,\n",
    "    t_pres=t_pres,\n",
    "    t_posts=t_posts,\n",
    "    fmin=fmin,\n",
    "    fmax=fmax,\n",
    "    zerophase=zerophase,\n",
    "    ylims=ylims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_misfits(\n",
    "    save_path,\n",
    "    epsilon,\n",
    "):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, sharex=\"all\", figsize=(8, 8))\n",
    "\n",
    "    update_folders = np.sort(\n",
    "        np.asarray(\n",
    "            [\n",
    "                int(f.strip(\"Update_\"))\n",
    "                for f in listdir(save_path)\n",
    "                if f.startswith(\"Update_\")\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    print(update_folders)\n",
    "           \n",
    "    Xs = np.array([np.load(join(save_path,f\"Update_{update_folders[up_nr]}\",f\"X1s_{epsilon}.npy\")) for up_nr in update_folders])\n",
    "    ms = np.arange(0,len(Xs))\n",
    "    Xs = Xs.min(axis=1)\n",
    "    ax.semilogy(ms,Xs)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=15)\n",
    "    ax.tick_params(axis=\"both\", which=\"minor\", labelsize=15)\n",
    "    ax.set_xlabel(\"Update nr\", fontsize=20)\n",
    "    ax.set_ylabel(\"Misfit\", fontsize=20)\n",
    "    ax.set_xticks(ms)\n",
    "    ax.set_xticklabels(ms)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_OG = \"/home/nienke/Documents/Research/SS_MTI/External_packages/Test_reflectivity/m0_gradient_descent/\"\n",
    "plot_misfits(save_path_OG,epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_exact(m:np.array):\n",
    "    \"\"\" \n",
    "    Step 1:\n",
    "    -- plug in only the moment tensor parameters in .dat file --\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" \n",
    "    Step 2:\n",
    "    -- Run dat file --\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" \n",
    "    Step 3:\n",
    "    -- Give back the data vector (i.e., part of the Green's function) --\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"forward run in iteration: {self.it}\")\n",
    "    if not exist(pjoin(self.f_dat_OG, f\"It_{self.it}\")):\n",
    "        makedirs(pjoin(self.f_dat_OG, f\"It_{self.it}\"))\n",
    "    self.f_dat = pjoin(self.f_dat_OG, f\"It_{self.it}\")\n",
    "    if self.it == 0:\n",
    "        subprocess.call(f\"scp {self.prior_dat_filepath} .\", shell=True, cwd=self.f_dat)\n",
    "    else:\n",
    "        prev_it = self.it - 1\n",
    "        prev_it_file = pjoin(self.f_dat_OG, f\"It_{prev_it}\", \"crfl.dat\")\n",
    "        subprocess.call(f\"scp {prev_it_file} .\", shell=True, cwd=self.f_dat)\n",
    "    \"\"\" step 1. plug in the model parameters in the .dat file (.tvel will be created)\"\"\"\n",
    "    create_tvel = True\n",
    "    tvel_file_name = f\"{m[-1]}\"\n",
    "    Create_Vmod.update_dat_file(\n",
    "        self.f_dat, m, self.vpvs, self.depth, create_tvel, tvel_file_name\n",
    "    )\n",
    "    \"\"\" step 2. copy binary file into datfile folder & run the dat file \"\"\"\n",
    "    subprocess.call(f\"scp {self.binary_file_path} .\", shell=True, cwd=self.f_dat)\n",
    "    subprocess.call(\"./crfl_sac\", shell=True, cwd=self.f_dat)\n",
    "    self.it += 1\n",
    "    \"\"\" step 3. read in the output of the run \"\"\"\n",
    "    np.save(pjoin(self.f_dat, \"m.npy\"), m)\n",
    "    return read_refl_mseeds(path=self.f_dat, dt=self.dt, stack=False)\n",
    "\n",
    "e1 = np.array([1, 0, 0, 0, 0, 0])\n",
    "e2 = np.array([0, 1, 0, 0, 0, 0])\n",
    "e3 = np.array([0, 0, 1, 0, 0, 0])\n",
    "e4 = np.array([0, 0, 0, 1, 0, 0])\n",
    "e5 = np.array([0, 0, 0, 0, 1, 0])\n",
    "e6 = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "# With subprocess, we can do this in parallel:\n",
    "G_1 = forward(e1)\n",
    "G_2 = forward(e2)\n",
    "G_3 = forward(e3)\n",
    "G_4 = forward(e4)\n",
    "G_5 = forward(e5)\n",
    "G_6 = forward(e6)\n",
    "\n",
    "m_depth = np.array([77])\n",
    "G_7 = forward(m_depth)\n",
    "\n",
    "G_approx = np.vstack((G_1, G_2, G_3, G_4,G_5,G_6,G_7))\n",
    "\n",
    "# Considering L2:\n",
    "dxi_ds = -2*(d_obs - d_syn) / sigma**2\n",
    "\n",
    "dxi_d_m = np.vdot(dxi_ds, G_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = \"/home/nienke/Documents/Research/SS_MTI/External_packages/reflectivity_Mars/SRC/test/crfl_sac\"\n",
    "save_path_OG = \"/home/nienke/Documents/Master/SS_MTI/External_packages/Test_reflectivity/Exact_Gradient\"\n",
    "if not exists(join(save_path_OG, \"start_v\")):\n",
    "    makedirs(join(save_path_OG, \"start_v\"))\n",
    "f_start = join(save_path_OG, \"start_v\")\n",
    "\n",
    "## Fixed parameters:\n",
    "src_depth = 20.0\n",
    "epi_in_km = 1774.7380\n",
    "epi = kilometer2degrees(epi_in_km, radius=3389.5)\n",
    "baz = 0.0\n",
    "\n",
    "dt = 0.025\n",
    "\n",
    "phases = [\"P\", \"S\", \"P\", \"S\", \"S\"]\n",
    "comps = [\"Z\", \"T\", \"R\", \"Z\", \"R\"]\n",
    "t_pres = [1, 1, 1, 1, 1]\n",
    "t_posts = [30, 30, 30, 30, 30]\n",
    "ylims = [1e-9, 1e-9, 2e-9, 3e-9, 2e-9]\n",
    "\n",
    "fmin = 0.2\n",
    "fmax = 0.6\n",
    "zerophase = False\n",
    "\n",
    "\n",
    "## Start parameters:\n",
    "bm_start_model = \"/home/nienke/Documents/Research/Data/MTI/MT_vs_STR/bm_models/TAYAK.bm\"\n",
    "m_rr = 0.2\n",
    "m_tt = 0.3\n",
    "m_pp = -0.4\n",
    "m_rt = -0.2\n",
    "m_rp = 0.3\n",
    "m_tp = 0.8\n",
    "focal_mech = [m_rr, m_tt, m_pp, m_rt, m_rp, m_tp]\n",
    "Moho_d = 24.0\n",
    "\n",
    "Create_Vmod.create_dat_file(\n",
    "    src_depth, epi_in_km, baz, focal_mech, dt, f_start, bm_start_model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_test = np.array([1, 0, 0, 0, 0, 0])\n",
    "Create_Vmod.update_dat_file(\n",
    "    dat_folder=f_start,\n",
    "    m=m_test,\n",
    "    vpvs=False,\n",
    "    depth=False,\n",
    "    produce_tvel= False,\n",
    "    tvel_name= \"Test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try BFGS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(\n",
    "    src_str.misfit,\n",
    "    m0,\n",
    "    st_obs_w,\n",
    "    method=\"BFGS\",\n",
    "    options={\n",
    "        \"maxiter\": 2,\n",
    "        \"eps\": eps_array,\n",
    "        \"return_all\": True,\n",
    "        \"gtol\": 1e-8,\n",
    "        \"disp\": True,\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
